import*as N from"csv-stream";import{open as x}from"node:fs/promises";import*as I from"post-entity";import C from"better-sqlite3";import{ensureFileSync as y}from"fs-extra";var a={},l=n=>(a[n]===void 0&&(y(n),a[n]=new C(n),a[n].exec("PRAGMA journal_mode = OFF;"),a[n].exec("PRAGMA synchronous = 0;"),a[n].exec("PRAGMA cache_size = 1000000;"),a[n].exec("PRAGMA locking_mode = EXCLUSIVE"),a[n].exec("PRAGMA temp_store = MEMORY;")),a[n]),R=n=>{a[n]=void 0},T=(n,t,e=void 0)=>{let o=n.prepare(t);return e===void 0?o.run():o.bind(e).run()},E=(n,t,e={})=>n.prepare(t).bind(e).all();import A from"wink-nlp";import O from"wink-eng-lite-web-model";import{rmSync as _}from"fs-extra";var U=/'/g,W=/[\n\r]/g,L=1e3*60*60,S=/\$/g,D=A(O),c={createWords:[`CREATE TABLE IF NOT EXISTS words (
     id INTEGER PRIMARY KEY,
     word TEXT UNIQUE
  );`],createWordHistory:[`CREATE TABLE IF NOT EXISTS word_history (
       id INTEGER PRIMARY KEY,
       account_id INTEGER NOT NULL,
       word_id INTEGER NOT NULL,
       timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
       FOREIGN KEY (word_id) REFERENCES words(id)
    );`,"CREATE INDEX IF NOT EXISTS account_idx ON word_history (account_id);","CREATE INDEX IF NOT EXISTS word_idx ON word_history (word_id);"],createAccounts:[`CREATE TABLE IF NOT EXISTS users (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      username TEXT NOT NULL
    );`,"CREATE INDEX IF NOT EXISTS idx_username ON users (username COLLATE NOCASE);"],insertNewWords:"INSERT OR IGNORE INTO words (word) VALUES $$;",insertNewWordHistory:"INSERT INTO word_history (account_id, word_id, timestamp) VALUES (:account_id, :word_id, DATETIME(:timestamp));",insertUser:"INSERT INTO users (username) VALUES (:username);",getNewWords:"SELECT id, word FROM words WHERE word IN $$;",getUser:"SELECT id, username FROM users WHERE username = :username LIMIT 1;",getUniqueWords:`SELECT 
      CAST(strftime('%s', strftime('%Y-%m-%d %H:00:00', timestamp)) AS INT) * 1000 AS hour, 
      COUNT(DISTINCT word_id) AS uniqueCount,
      COUNT(word_id) AS count,
      COUNT(DISTINCT word_id) / COUNT(word_id) AS ratio
    FROM word_history
    WHERE account_id = :account_id
    GROUP BY hour
    ORDER BY hour ASC;`,getWordHistory:`SELECT 
      CAST(strftime('%s', strftime('%Y-%m-%d %H:00:00', timestamp)) AS INT) * 1000 AS hour, 
      word_id
    FROM word_history
    WHERE account_id = :account_id
    ORDER BY hour ASC;`,getWords:"SELECT id, word FROM words;"},f=class{constructor(t=__dirname+"/../../../assets/wordCache.db",e=!0){this.cache={};this.path=t,e&&this.connect(t)}connect(t=this.path){return this.connection=l(t),c.createWords.forEach(e=>this.connection.exec(e)),c.createWordHistory.forEach(e=>this.connection.exec(e)),c.createAccounts.forEach(e=>this.connection.exec(e)),this.populate(),this}getUserId(t){if(typeof t=="number")return t;let e=E(this.connection,c.getUser,{username:t});return e.length>0?e[0].id:T(this.connection,c.insertUser,{username:t}).lastInsertRowid}getReport(t){let e=E(this.connection,c.getUniqueWords,{account_id:t});if(e.length===0)return[];let o=E(this.connection,c.getWordHistory,{account_id:t}),r=e[0].hour,u=e[e.length-1].hour+1,s=[],i=[],d=[];for(;r<u;r+=L){s.push(r);let h=e.find(m=>m.hour===r);h===void 0?(i.push(0),d.push(0)):(i.push(h.uniqueCount),d.push(h.count))}let p=[];return s.map((h,m)=>{let g=0;return o.filter(w=>w.hour===h).forEach(w=>{p.indexOf(w.word_id)===-1&&(g+=1,p.push(w.word_id))}),{hour:h,count:d[m],uniqueCount:i[m],ratio:d[m]===0?0:i[m]/d[m],newGrammar:g}})}reset(){return this.connection&&this.connection.close(),R(this.path),_(this.path),this}addUsages(t,e,o){let r=this.getUserId(e),u=o instanceof Date?o.toISOString().slice(0,-5):o;for(let s of Object.keys(t)){let i=t[s];for(let d=0;d<i.amount;d++)this.addUsage(i.id,r,u)}return r}addUsage(t,e,o){return T(this.connection,c.insertNewWordHistory,{word_id:t,account_id:e,timestamp:o}),this}fetch(t){let e=this.tokenize(t),o=[],r={};for(let s of e)this.cache[s]===void 0?o.push(s):(r[s]===void 0&&(r[s]={id:this.cache[s],amount:0}),r[s].amount+=1);let u=this.getsert(o);for(let s of u)this.cache[s.word]=s.id,r[s.word]===void 0&&(r[s.word]={id:this.cache[s.word],amount:0}),r[s.word].amount+=1;return r}tokenize(t){return D.readDoc(t.toLowerCase().replace(U,"").replace(W," ")).tokens().out()}populate(){let t=E(this.connection,c.getWords);for(let e of t)this.cache[e.word]=e.id;return this}getsert(t){let e=t instanceof Array?t:this.tokenize(t);if(e.length===0)return[];let o=`('${e.join("'), ('")}')`.replace(S,"S");T(this.connection,c.insertNewWords.replace("$$",o));let r=`('${e.join("', '")}')`.replace(S,"S");return E(this.connection,c.getNewWords.replace("$$",r),{})}toTimeSeries(t,e){let o=[];for(let r of t){let u=r[e];o.push({date:r.hour.toString(),value:u})}return o}};var b=process.argv[2]||"";if(b==="")throw new RangeError;var M={delimiter:"	",endLine:`
`,columnOffset:0,escapeChar:'"',enclosedChar:'"'},q=N.createStream(M);async function k(){let n=new f(`${process.cwd()}/tests/test.db`,!1).reset().connect(),t;(await x(b,"r")).createReadStream().pipe(q).on("data",function(r){if(r.retweet!=="False"||r.language!=="en")return;let u=r.tweet.toLowerCase(),s=I.process(u).filter(i=>i.type==="text").map(i=>i.raw.trim());for(let i of s){let d=n.fetch(i);t=n.addUsages(d,r.username,new Date(r.created_at))}}).on("close",function(){let r=n.getReport(t);console.log(JSON.stringify(r))})}k();
//# sourceMappingURL=index.js.map